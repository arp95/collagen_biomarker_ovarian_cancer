{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "711e0b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header files loaded!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# header files\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.metrics import (\n",
    "    concordance_index_censored,\n",
    "    concordance_index_ipcw,\n",
    "    cumulative_dynamic_auc,\n",
    "    integrated_brier_score,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_regression, f_classif\n",
    "from datetime import datetime\n",
    "plt.figure(figsize=(10,10))\n",
    "print(\"Header files loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8527b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "is_ovarian_cancer = 1\n",
    "is_cervix_cancer = 0\n",
    "is_endometrial_cancer = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f13ed4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "# load ovarian cancer files\n",
    "if is_ovarian_cancer:\n",
    "    oc_files = (glob.glob(\"../results/oc_collagen_features/window_1/*\"))\n",
    "    print(len(oc_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b002baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect features\n",
    "if is_ovarian_cancer:\n",
    "    collagen_features = []\n",
    "    for file in oc_files:\n",
    "        filename = file.split(\"/\")[-1]\n",
    "        flag = -1\n",
    "        file_features = []\n",
    "        with open(file, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/window_2/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/window_3/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/window_4/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/window_5/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/window_6/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/window_7/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/window_8/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/window_9/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "        collagen_features.append(file_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b76ee33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['patient_name', 'SF1', 'SF2', 'SF3', 'SF4', 'SF5', 'SF6', 'SF7', 'cont_risk_score', 'binary_risk_score', 'WSI_Width', 'WSI_Height', 'year_of_birth', 'race', 'year_of_death', 'vital_status', 'Organ', 'treatment_type', 'Age', 'TTE', 'censor', 'Site', 'stage', 'OS_days', 'Vital', 'stage_numeric']\n",
      "95\n",
      "95\n",
      "95\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "# create output survival information for training model and get til features\n",
    "if is_ovarian_cancer:\n",
    "    til_features = []\n",
    "    censor = []\n",
    "    days = []\n",
    "    filenames = []\n",
    "    flag = -1\n",
    "    with open(\"../results/DATA_OC.csv\", newline='', encoding = \"ISO-8859-1\") as csvfile:\n",
    "        spamreader = csv.reader(csvfile)\n",
    "        for row in spamreader:\n",
    "            if flag == -1:\n",
    "                flag = 1\n",
    "                print(row)\n",
    "            else:\n",
    "                array = row\n",
    "                filenames.append(array[0])\n",
    "                f_features = [float(array[1]), float(array[2]), float(array[3]), float(array[4]), float(array[5]), float(array[6]), float(array[7])]\n",
    "                til_features.append(f_features)\n",
    "                censor.append(bool(int(array[20])))\n",
    "                days.append(int(array[23]))\n",
    "                \n",
    "    final_til_features = []\n",
    "    y = []\n",
    "    event = []\n",
    "    survival_time = []\n",
    "    for file in oc_files:\n",
    "        count = 0\n",
    "        filename1 = file.split(\"/\")[-1][:-4]\n",
    "        for filename in filenames:\n",
    "            filename2 = filename\n",
    "            if filename1 == filename2:\n",
    "                final_til_features.append(til_features[count])\n",
    "                y.append([censor[count], days[count]])\n",
    "                event.append(censor[count])\n",
    "                survival_time.append(days[count])\n",
    "            count += 1\n",
    "    print(len(final_til_features))\n",
    "    print(len(y))\n",
    "    print(len(event))\n",
    "    print(len(survival_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510ffae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# generate training set for training model\n",
    "features = []\n",
    "for index in range(0, len(oc_files)):\n",
    "    #features.append(final_til_features[index]+collagen_features[index])\n",
    "    features.append(collagen_features[index])\n",
    "    #features.append(final_til_features[index])\n",
    "print(len(features))\n",
    "print(len(features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb55c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final training information to be used for training model\n",
    "features = np.array(features)\n",
    "y = np.array(y)\n",
    "event = np.array(event)\n",
    "survival_time = np.array(survival_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30438eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main code for training\n",
    "iter_scores = []\n",
    "max_score = -1\n",
    "dt = dtype=[('Status', '?'), ('Survival_in_days', '<f8')]\n",
    "for iter in range(100):\n",
    "    model_score = []\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    for train_index, test_index in kf.split(features):\n",
    "        # get the training and validation data\n",
    "        features_train, features_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        event_train, survival_time_train = event[train_index], survival_time[train_index]\n",
    "        event_test, survival_time_test = event[test_index], survival_time[test_index]\n",
    "        y_train = np.array([tuple(row) for row in y_train], dtype=dt)\n",
    "        y_test = np.array([tuple(row) for row in y_test], dtype=dt)\n",
    "        \n",
    "        # feature selection\n",
    "        scaler = MinMaxScaler()\n",
    "        features_train = scaler.fit_transform(features_train)\n",
    "        features_test = scaler.transform(features_test)\n",
    "        select = SelectKBest(score_func=chi2, k=len(features[0])-4)\n",
    "        features_train_selected = select.fit_transform(features_train, survival_time_train)\n",
    "        features_test_selected = select.transform(features_test)\n",
    "        features_train_df = pd.DataFrame(features_train_selected)\n",
    "        features_test_df = pd.DataFrame(features_test_selected)\n",
    "        \n",
    "        # fit model\n",
    "        estimator = CoxnetSurvivalAnalysis(l1_ratio=0.9, alpha_min_ratio=0.001)\n",
    "        estimator.fit(features_train_df, y_train)\n",
    "        \n",
    "        # score on validation set\n",
    "        score, _, _, _, _ = concordance_index_censored(event_test, survival_time_test, estimator.predict(features_test_df))\n",
    "        model_score.append(score)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "    \n",
    "    if len(model_score) > 0:\n",
    "        iter_scores.append(np.mean(model_score))\n",
    "        max_score = max(max(model_score), max_score)\n",
    "print(np.mean(iter_scores), np.std(iter_scores))\n",
    "print(max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d6950b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CoxnetSurvivalAnalysis(alpha_min_ratio=0.1, l1_ratio=0.9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model to be used for external validation\n",
    "features_train = features\n",
    "y_train = y\n",
    "event_train, survival_time_train = event, survival_time\n",
    "dt = dtype=[('Status', '?'), ('Survival_in_days', '<f8')]\n",
    "y_train = np.array([tuple(row) for row in y_train], dtype=dt)\n",
    "        \n",
    "# feature selection\n",
    "scaler = MinMaxScaler()\n",
    "features_train = scaler.fit_transform(features_train)\n",
    "features_train_df = pd.DataFrame(features_train)\n",
    "        \n",
    "# fit model\n",
    "estimator = CoxnetSurvivalAnalysis(l1_ratio=0.9, alpha_min_ratio=0.1)\n",
    "estimator.fit(features_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54e50739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "11\n",
      "12\n",
      "16\n",
      "17\n",
      "19\n",
      "21\n",
      "23\n",
      "25\n",
      "\n",
      "Prognostic features count = 9\n"
     ]
    }
   ],
   "source": [
    "# find prognostic features from model trained above\n",
    "count = 0\n",
    "for index1 in range(0, len(estimator.coef_)):\n",
    "    flag = -1\n",
    "    for index2 in range(0, len(estimator.coef_[index1])):\n",
    "        if estimator.coef_[index1][index2] > 0:\n",
    "            flag = 1\n",
    "            print(index1)\n",
    "            break\n",
    "    if flag == 1:\n",
    "        count += 1\n",
    "print()\n",
    "print(\"Prognostic features count = \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193a41c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5cc6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3b1347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "date_format = \"%m/%d/%Y\"\n",
    "is_ovarian_cancer = 1\n",
    "is_cervix_cancer = 0\n",
    "is_endometrial_cancer = 0\n",
    "\n",
    "def mean(a):\n",
    "    return sum(a) / len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac941f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Copath', 'Diagnosis date', 'Last follow up', 'Date recurred ', 'Date of death', 'BMI', 'BMI_binary [1=obese]', 'CTx', 'RTx [1=VB,2=EBRT,3=palliative]', 'Comorb_HTN', 'Comorb_DM', 'Comorb_Hyperlip ']\n",
      "122\n",
      "122\n",
      "122\n"
     ]
    }
   ],
   "source": [
    "test_censor_1 = []\n",
    "test_days_1 = []\n",
    "test_filenames_1 = []\n",
    "flag = -1\n",
    "with open(\"../../../Desktop/uh_ec.csv\", newline='', encoding = \"ISO-8859-1\") as csvfile:\n",
    "    spamreader = csv.reader(csvfile)\n",
    "    for row in spamreader:\n",
    "        if flag == -1:\n",
    "            flag = 1\n",
    "            print(row)\n",
    "        else:\n",
    "            array = row\n",
    "            \n",
    "            if array[1] == \"\":\n",
    "                continue\n",
    "            \n",
    "            test_filenames_1.append(array[0])\n",
    "            if array[4] == \"0\":\n",
    "                test_censor_1.append(False)\n",
    "                \n",
    "                first_date = datetime.strptime(str(array[1]), date_format)\n",
    "                last_date = datetime.strptime(str(array[2]), date_format)\n",
    "                delta = last_date - first_date\n",
    "                test_days_1.append(delta.days)\n",
    "            else:\n",
    "                test_censor_1.append(True)\n",
    "                \n",
    "                first_date = datetime.strptime(str(array[1]), date_format)\n",
    "                last_date = datetime.strptime(str(array[4]), date_format)\n",
    "                delta = last_date - first_date\n",
    "                test_days_1.append(delta.days)\n",
    "print(len(test_filenames_1))\n",
    "print(len(test_censor_1))\n",
    "print(len(test_days_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37871db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TMA #', 'TMA ID', 'TMA_block', 'Copath', 'Race', 'Age', 'Histotype_NEW', 'Mol_Subtype', 'Grade_binary_NEW', 'Myoinv_NEW', 'LVI_NEW', 'LN_NEW', 'Stage_NEW', 'BMI', 'BMI_binary [1=obese]', 'DFS [months]', 'DFS status [1=recurred]', 'OS [months]', 'OS status [1=dead]', 'CD3av', 'CD8av', 'CD4av', 'CD4/8ratio', 'FoxP3av', 'FoxP3/CD8ratio', 'PD1_TILav', 'PDL1_TILav', 'PDL1TILs_binary', 'CDK5_binary']\n",
      "121\n",
      "121\n",
      "121\n",
      "121\n"
     ]
    }
   ],
   "source": [
    "test_filenames_2 = []\n",
    "test_genes_1 = []\n",
    "test_genes_2 = []\n",
    "test_genes_3 = []\n",
    "flag = -1\n",
    "with open(\"../../../Desktop/uh_ec_genetic.csv\", newline='', encoding = \"ISO-8859-1\") as csvfile:\n",
    "    spamreader = csv.reader(csvfile)\n",
    "    for row in spamreader:\n",
    "        if flag == -1:\n",
    "            flag = 1\n",
    "            print(row)\n",
    "        else:\n",
    "            array = row\n",
    "            \n",
    "            if array[1] == \"\":\n",
    "                continue\n",
    "            \n",
    "            test_filenames_2.append(array[3])\n",
    "            \n",
    "            if array[7] == \"Cnlo\":\n",
    "                test_genes_2.append(1)\n",
    "            else:\n",
    "                test_genes_2.append(0)\n",
    "            \n",
    "            if array[7] == \"Cnhigh\":\n",
    "                test_genes_1.append(1)\n",
    "            else:\n",
    "                test_genes_1.append(0)\n",
    "                \n",
    "            if array[7] == \"MMRabnormal\":\n",
    "                test_genes_3.append(1)\n",
    "            else:\n",
    "                test_genes_3.append(0)\n",
    "            \n",
    "print(len(test_filenames_2))\n",
    "print(len(test_genes_1))\n",
    "print(len(test_genes_2))\n",
    "print(len(test_genes_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2347570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "test_filenames = []\n",
    "test_days = []\n",
    "test_censor = []\n",
    "test_genes_high = []\n",
    "test_genes_low = []\n",
    "test_genes_mmr = []\n",
    "for index in range(0, len(test_filenames_1)):\n",
    "    for index1 in range(0, len(test_filenames_2)):\n",
    "        if test_filenames_1[index] == test_filenames_2[index1]:\n",
    "            test_filenames.append(test_filenames_1[index])\n",
    "            test_days.append(test_days_1[index])\n",
    "            test_censor.append(test_censor_1[index])\n",
    "            test_genes_high.append(test_genes_1[index1])\n",
    "            test_genes_low.append(test_genes_2[index1])\n",
    "            test_genes_mmr.append(test_genes_3[index1])\n",
    "            break\n",
    "print(len(test_filenames))\n",
    "print(len(test_days))\n",
    "print(len(test_censor))\n",
    "print(len(test_genes_high))\n",
    "print(len(test_genes_low))\n",
    "print(len(test_genes_mmr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5a99235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S06-10610\n",
      "3360\n",
      "True\n",
      "0\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(test_filenames[0])\n",
    "print(test_days[0])\n",
    "print(test_censor[0])\n",
    "print(test_genes_high[0])\n",
    "print(test_genes_low[0])\n",
    "print(test_genes_mmr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c62cd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S09-1524\n",
      "3350\n",
      "False\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(test_filenames[50])\n",
    "print(test_days[50])\n",
    "print(test_censor[50])\n",
    "print(test_genes_high[50])\n",
    "print(test_genes_low[50])\n",
    "print(test_genes_mmr[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a8058a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7af607d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n"
     ]
    }
   ],
   "source": [
    "test_ec_files = (glob.glob(\"../../uh_endometrial_cancer/collagen_feature_maps_200_final/*\"))\n",
    "print(len(test_ec_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5f7fb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "test_final_filenames = []\n",
    "test_final_censor = []\n",
    "test_final_days = []\n",
    "test_final_genes_high = []\n",
    "test_final_genes_low = []\n",
    "test_final_genes_mmr = []\n",
    "index = 0\n",
    "for file in test_filenames:\n",
    "    flag = -1\n",
    "    for file_1 in test_ec_files:\n",
    "        if file in file_1:\n",
    "            test_final_filenames.append(test_filenames[index])\n",
    "            test_final_censor.append(test_censor[index])\n",
    "            test_final_days.append(test_days[index])\n",
    "            test_final_genes_high.append(test_genes_high[index])\n",
    "            test_final_genes_low.append(test_genes_low[index])\n",
    "            test_final_genes_mmr.append(test_genes_mmr[index])\n",
    "            flag = 1\n",
    "            break\n",
    "    index += 1\n",
    "print(len(test_final_filenames))\n",
    "print(len(test_final_censor))\n",
    "print(len(test_final_days))\n",
    "print(len(test_final_genes_high))\n",
    "print(len(test_final_genes_low))\n",
    "print(len(test_final_genes_mmr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c48a0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, False, True, True, False, False, True, False, True, False, False, True, True, False, False, False, True, False, False, False, False, False, True, False, False, True, True, False, False, False, False, True, True, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, True, False, True, False, False, False, True, True, True, False, False, True, True, False, False, False, True, False, False, False, False, True, True, True, False, False, True, True, True, False, False, True, False, True, True, False, False, False, True]\n"
     ]
    }
   ],
   "source": [
    "print(test_final_censor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f63fe67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for index in range(0, len(test_final_censor)):\n",
    "    if test_final_censor[index] == False:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6504649a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# collect features\n",
    "test_collagen_features = []\n",
    "for file in test_final_filenames:\n",
    "    file_features = []\n",
    "        \n",
    "    for file_1 in test_ec_files:\n",
    "        if file in file_1:\n",
    "            filename = file_1.split(\"/\")[-1]\n",
    "            flag = -1\n",
    "            slide_features = []\n",
    "            \n",
    "            with open(file_1, newline='') as csvfile:\n",
    "                spamreader = csv.reader(csvfile)\n",
    "                for row in spamreader:\n",
    "                    if flag == -1:\n",
    "                        array = row\n",
    "                        for index in range(0, len(array)-1):\n",
    "                            slide_features.append(float(array[index]))\n",
    "                    \n",
    "            with open(\"../../uh_endometrial_cancer/collagen_feature_maps_250_final/\" + filename, newline='') as csvfile:\n",
    "                spamreader = csv.reader(csvfile)\n",
    "                for row in spamreader:\n",
    "                    if flag == -1:\n",
    "                        array = row\n",
    "                        for index in range(0, len(array)-1):\n",
    "                            slide_features.append(float(array[index]))\n",
    "                    \n",
    "            with open(\"../../uh_endometrial_cancer/collagen_feature_maps_300_final/\" + filename, newline='') as csvfile:\n",
    "                spamreader = csv.reader(csvfile)\n",
    "                for row in spamreader:\n",
    "                    if flag == -1:\n",
    "                        array = row\n",
    "                        for index in range(0, len(array)-1):\n",
    "                            slide_features.append(float(array[index]))\n",
    "                    \n",
    "            with open(\"../../uh_endometrial_cancer/collagen_feature_maps_350_final/\" + filename, newline='') as csvfile:\n",
    "                spamreader = csv.reader(csvfile)\n",
    "                for row in spamreader:\n",
    "                    if flag == -1:\n",
    "                        array = row\n",
    "                        for index in range(0, len(array)-1):\n",
    "                            slide_features.append(float(array[index]))\n",
    "                    \n",
    "            with open(\"../../uh_endometrial_cancer/collagen_feature_maps_400_final/\" + filename, newline='') as csvfile:\n",
    "                spamreader = csv.reader(csvfile)\n",
    "                for row in spamreader:\n",
    "                    if flag == -1:\n",
    "                        array = row\n",
    "                        for index in range(0, len(array)-1):\n",
    "                            slide_features.append(float(array[index]))\n",
    "                    \n",
    "            with open(\"../../uh_endometrial_cancer/collagen_feature_maps_450_final/\" + filename, newline='') as csvfile:\n",
    "                spamreader = csv.reader(csvfile)\n",
    "                for row in spamreader:\n",
    "                    if flag == -1:\n",
    "                        array = row\n",
    "                        for index in range(0, len(array)-1):\n",
    "                            slide_features.append(float(array[index]))\n",
    "                    \n",
    "            with open(\"../../uh_endometrial_cancer/collagen_feature_maps_500_final/\" + filename, newline='') as csvfile:\n",
    "                spamreader = csv.reader(csvfile)\n",
    "                for row in spamreader:\n",
    "                    if flag == -1:\n",
    "                        array = row\n",
    "                        for index in range(0, len(array)-1):\n",
    "                            slide_features.append(float(array[index]))\n",
    "                    \n",
    "            with open(\"../../uh_endometrial_cancer/collagen_feature_maps_550_final/\" + filename, newline='') as csvfile:\n",
    "                spamreader = csv.reader(csvfile)\n",
    "                for row in spamreader:\n",
    "                    if flag == -1:\n",
    "                        array = row\n",
    "                        for index in range(0, len(array)-1):\n",
    "                            slide_features.append(float(array[index]))\n",
    "                    \n",
    "            with open(\"../../uh_endometrial_cancer/collagen_feature_maps_600_final/\" + filename, newline='') as csvfile:\n",
    "                spamreader = csv.reader(csvfile)\n",
    "                for row in spamreader:\n",
    "                    if flag == -1:\n",
    "                        array = row\n",
    "                        for index in range(0, len(array)-1):\n",
    "                            slide_features.append(float(array[index]))\n",
    "            file_features.append(slide_features)\n",
    "    \n",
    "    f = [sum(col) / float(len(col)) for col in zip(*file_features)]\n",
    "    test_collagen_features.append(f)\n",
    "print(len(test_collagen_features))\n",
    "print(len(test_collagen_features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27853c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    }
   ],
   "source": [
    "test_y = []\n",
    "test_event = []\n",
    "test_survival_time = []\n",
    "for index in range(0, len(test_final_censor)):\n",
    "    test_y.append([test_final_censor[index], test_final_days[index]])\n",
    "    test_event.append(test_final_censor[index])\n",
    "    test_survival_time.append(test_final_days[index])\n",
    "print(len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e86c557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n",
      "27\n",
      "[1.9329666666666665, 0.2464666666666667, 2.2958666666666665, 1.9857666666666667, 0.3131933333333334, 2.2970666666666664, 2.021733333333333, 0.3066466666666667, 2.2968333333333333, 2.0467999999999997, 0.3766966666666667, 2.2959666666666667, 2.0687333333333333, 0.44312666666666667, 2.2950999999999997, 2.0825666666666667, 0.36338, 2.2917666666666663, 2.0981, 0.42194000000000004, 2.2913, 2.1118666666666663, 0.4701633333333333, 2.2914333333333334, 2.1183666666666667, 0.43571999999999994, 2.290366666666667]\n"
     ]
    }
   ],
   "source": [
    "# generate training set for training model\n",
    "test_features = []\n",
    "for index in range(0, len(test_final_filenames)):\n",
    "    #test_features.append(test_collagen_features[index] + [test_final_genes_high[index]] + [test_final_genes_low[index]] + [test_final_genes_mmr[index]])\n",
    "    test_features.append(test_collagen_features[index])\n",
    "    #features.append(final_til_features[index])\n",
    "print(len(test_features))\n",
    "print(len(test_features[0]))\n",
    "print(test_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "daa0e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final training information to be used for training model\n",
    "test_features = np.array(test_features)\n",
    "test_y = np.array(test_y)\n",
    "test_event = np.array(test_event)\n",
    "test_survival_time = np.array(test_survival_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main code for training\n",
    "iter_scores = []\n",
    "max_score = -1\n",
    "dt = dtype=[('Status', '?'), ('Survival_in_days', '<f8')]\n",
    "for iter in range(100):\n",
    "    model_score = []\n",
    "    kf = KFold(n_splits=5, shuffle=True)\n",
    "    for train_index, test_index in kf.split(test_features):\n",
    "        # get the training and validation data\n",
    "        features_train, features_test = test_features[train_index], test_features[test_index]\n",
    "        y_train, y_test = test_y[train_index], test_y[test_index]\n",
    "        event_train, survival_time_train = test_event[train_index], test_survival_time[train_index]\n",
    "        event_test, survival_time_test = test_event[test_index], test_survival_time[test_index]\n",
    "        y_train = np.array([tuple(row) for row in y_train], dtype=dt)\n",
    "        y_test = np.array([tuple(row) for row in y_test], dtype=dt)\n",
    "        \n",
    "        # feature selection\n",
    "        scaler = MinMaxScaler()\n",
    "        features_train = scaler.fit_transform(features_train)\n",
    "        features_test = scaler.transform(features_test)\n",
    "        select = SelectKBest(score_func=chi2, k=len(test_features[0])-8)\n",
    "        features_train_selected = select.fit_transform(features_train, survival_time_train)\n",
    "        features_test_selected = select.transform(features_test)\n",
    "        features_train_df = pd.DataFrame(features_train_selected)\n",
    "        features_test_df = pd.DataFrame(features_test_selected)\n",
    "        \n",
    "        # fit model\n",
    "        estimator = CoxnetSurvivalAnalysis(l1_ratio=0.9, alpha_min_ratio=0.001)\n",
    "        estimator.fit(features_train_df, y_train)\n",
    "        \n",
    "        # score on validation set\n",
    "        score, _, _, _, _ = concordance_index_censored(event_test, survival_time_test, estimator.predict(features_test_df))\n",
    "        model_score.append(score)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "    \n",
    "    if len(model_score) > 0:\n",
    "        iter_scores.append(np.mean(model_score))\n",
    "        max_score = max(max(model_score), max_score)\n",
    "print(np.mean(iter_scores), np.std(iter_scores))\n",
    "print(max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b09ad12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CoxnetSurvivalAnalysis(alpha_min_ratio=0.1, l1_ratio=0.9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model to be used for external validation\n",
    "features_train = features\n",
    "y_train = test_y\n",
    "event_train, survival_time_train = test_event, test_survival_time\n",
    "dt = dtype=[('Status', '?'), ('Survival_in_days', '<f8')]\n",
    "y_train = np.array([tuple(row) for row in y_train], dtype=dt)\n",
    "        \n",
    "# feature selection\n",
    "scaler = MinMaxScaler()\n",
    "features_train = scaler.fit_transform(features_train)\n",
    "features_train_df = pd.DataFrame(features_train)\n",
    "\n",
    "# print feature indexes selected\n",
    "selected_indexes = []\n",
    "for index in range(0, len(features_train[0])):\n",
    "    flag = -1\n",
    "    for index1 in range(0, len(features_train[0])):\n",
    "        if features_train[0, index] == features_train[0, index1]:\n",
    "            flag = 1\n",
    "            break\n",
    "    if flag == 1:\n",
    "        selected_indexes.append(index)\n",
    "print(\"Selected Features: \" + str(selected_indexes))\n",
    "\n",
    "\n",
    "# fit model\n",
    "estimator = CoxnetSurvivalAnalysis(l1_ratio=0.9, alpha_min_ratio=0.1)\n",
    "estimator.fit(features_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90485a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "4\n",
      "10\n",
      "13\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "22\n",
      "23\n",
      "26\n",
      "\n",
      "Prognostic features count = 12\n"
     ]
    }
   ],
   "source": [
    "# find prognostic features from model trained above\n",
    "count = 0\n",
    "for index1 in range(0, len(estimator.coef_)):\n",
    "    flag = -1\n",
    "    for index2 in range(0, len(estimator.coef_[index1])):\n",
    "        if estimator.coef_[index1][index2] > 0:\n",
    "            flag = 1\n",
    "            print(index1)\n",
    "            break\n",
    "    if flag == 1:\n",
    "        count += 1\n",
    "print()\n",
    "print(\"Prognostic features count = \" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24148b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122d3334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f622393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with test data\n",
    "test_oc_files = (glob.glob(\"../results/oc_collagen_features/test_window_1/*\"))\n",
    "print(len(test_oc_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f7c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect test features\n",
    "is_ovarian_cancer = 1\n",
    "if is_ovarian_cancer:\n",
    "    test_collagen_features = []\n",
    "    for file in test_oc_files:\n",
    "        filename = file.split(\"/\")[-1]\n",
    "        flag = -1\n",
    "        file_features = []\n",
    "        with open(file, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/test_window_2/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/test_window_3/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/test_window_4/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/test_window_5/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/test_window_6/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/test_window_7/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/test_window_8/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "                    \n",
    "        with open(\"../results/oc_collagen_features/test_window_9/\" + filename, newline='') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            for row in spamreader:\n",
    "                if flag == -1:\n",
    "                    array = row\n",
    "                    for index in range(0, len(array)-1):\n",
    "                        file_features.append(float(array[index]))\n",
    "        test_collagen_features.append(file_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a6746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_til_features = []\n",
    "test_filenames = []\n",
    "flag = -1\n",
    "with open(\"../results/DATA_UPMC.csv\", newline='', encoding = \"ISO-8859-1\") as csvfile:\n",
    "    spamreader = csv.reader(csvfile)\n",
    "    for row in spamreader:\n",
    "        if flag == -1:\n",
    "            flag = 1\n",
    "            print(row)\n",
    "        else:\n",
    "            array = row\n",
    "            test_filenames.append(array[0])\n",
    "            f_features = [float(array[1]), float(array[2]), float(array[3]), float(array[4]), float(array[5]), float(array[6]), float(array[7])]\n",
    "            test_til_features.append(f_features)\n",
    "\n",
    "final_test_til_features = []\n",
    "for file in test_oc_files:\n",
    "    count = 0\n",
    "    filename1 = file.split(\"/\")[-1][:-7]\n",
    "    for filename in test_filenames:\n",
    "        filename2 = filename\n",
    "        if filename1 == filename2:\n",
    "            final_test_til_features.append(test_til_features[count])\n",
    "        count += 1\n",
    "print(len(final_test_til_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d0598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate training set for testing model\n",
    "test_features = []\n",
    "for index in range(0, len(test_oc_files)):\n",
    "    #test_features.append(final_test_til_features[index] + test_collagen_features[index])\n",
    "    test_features.append(test_collagen_features[index])\n",
    "    #test_features.append(final_test_til_features[index])\n",
    "print(len(test_features))\n",
    "print(len(test_features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af4ffd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5339966832504146\n",
      "30\n",
      "57\n",
      "87\n"
     ]
    }
   ],
   "source": [
    "# run on test set\n",
    "features_train = features\n",
    "features_test = test_features\n",
    "y_train = y\n",
    "event_train, survival_time_train = event, survival_time\n",
    "dt = dtype=[('Status', '?'), ('Survival_in_days', '<f8')]\n",
    "y_train = np.array([tuple(row) for row in y_train], dtype=dt)\n",
    "scaler = MinMaxScaler()\n",
    "features_train = scaler.fit_transform(features_train)\n",
    "features_test = scaler.transform(features_test)\n",
    "features_train_df = pd.DataFrame(features_train)\n",
    "features_test_df = pd.DataFrame(features_test)\n",
    "        \n",
    "# fit model\n",
    "estimator = CoxnetSurvivalAnalysis(l1_ratio=0.9, alpha_min_ratio=0.01)\n",
    "estimator.fit(features_train_df, y_train)\n",
    "\n",
    "score, _, _, _, _ = concordance_index_censored(test_event, test_survival_time, estimator.predict(features_test_df))\n",
    "print(score)\n",
    "\n",
    "# get risk scores\n",
    "train_risk_scores = estimator.predict(features_train_df)\n",
    "test_risk_scores = estimator.predict(features_test_df)\n",
    "\n",
    "group = []\n",
    "median = np.median(train_risk_scores)\n",
    "count_low = 0\n",
    "count_high = 0\n",
    "for index in range(0, len(test_risk_scores)):\n",
    "    if test_risk_scores[index] > median:\n",
    "        count_high += 1\n",
    "        group.append(1)\n",
    "    else:\n",
    "        count_low += 1\n",
    "        group.append(0)\n",
    "print(count_low)\n",
    "print(count_high)\n",
    "print(len(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a703d88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1; 0; 1; 1; 0; 0; 1; 0; 1; 0; 0; 1; 1; 0; 0; 0; 1; 0; 0; 0; 0; 0; 1; 0; 0; 1; 1; 0; 0; 0; 0; 1; 1; 0; 0; 0; 0; 1; 0; 0; 0; 0; 1; 0; 0; 0; 0; 0; 1; 0; 1; 0; 0; 0; 1; 1; 1; 0; 0; 1; 1; 0; 0; 0; 1; 0; 0; 0; 0; 1; 1; 1; 0; 0; 1; 1; 1; 0; 0; 1; 0; 1; 1; 0; 0; 0; 1\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "for index in range(0, len(test_event)):\n",
    "    if test_event[index] == False:\n",
    "        a.append(0)\n",
    "    else:\n",
    "        a.append(1)\n",
    "print(*a, sep=\"; \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45b5ca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381; 4356; 442; 2586; 4021; 3; 2133; 1336; 748; 3691; 2107; 3245; 839; 4136; 3; 4102; 872; 846; 3556; 148; 3515; 3716; 2753; 16; 3072; 2418; 1931; 3166; 3422; 2972; 2660; 524; 1481; 1004; 2454; 1431; 10; 577; 3055; 2730; 1; 3; 780; 13; 3031; 2981; 2692; 3004; 1476; 2572; 1391; 1751; 2525; 2526; 233; 889; 1804; 197; 1311; 904; 121; 2178; 1198; 2588; 1679; 2575; 2218; 1075; 2198; 1486; 553; 682; 2005; 2310; 666; 1256; 2; 2012; 74; 409; 1153; 521; 196; 2281; 2241; 2211; 639\n"
     ]
    }
   ],
   "source": [
    "print(*test_survival_time, sep=\"; \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b098a368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1; 1; 1; 1; 1; 1; 1; 1; 0; 1; 0; 1; 0; 1; 0; 0; 0; 0; 0; 1; 1; 1; 1; 1; 0; 1; 1; 1; 1; 1; 0; 0; 1; 1; 0; 0; 0; 1; 0; 1; 0; 1; 1; 1; 1; 0; 0; 1; 1; 1; 1; 1; 1; 1; 0; 1; 1; 0; 1; 1; 0; 0; 0; 1; 1; 1; 0; 1; 0; 1; 1; 1; 1; 1; 1; 0; 1; 0; 1; 1; 1; 1; 0; 0; 1; 0; 1\n"
     ]
    }
   ],
   "source": [
    "print(*group, sep=\"; \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691df8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_high)\n",
    "for index in range(0, len(test_oc_files)):\n",
    "    if test_risk_scores[index] > median:\n",
    "        print(test_oc_files[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80faf9bb",
   "metadata": {},
   "source": [
    "row_1 = []\n",
    "row_2 = []\n",
    "row_3 = []\n",
    "row_4 = []\n",
    "for index in range(0, len(test_oc_files)):\n",
    "    filename = test_oc_files[index].split(\"/\")[-1][:-8]\n",
    "    flag = 0\n",
    "    flag_category = \"low\"\n",
    "    if test_risk_scores[index] > median:\n",
    "        flag = 1\n",
    "        flag_category = \"high\"\n",
    "    row_1.append(str(filename))\n",
    "    row_2.append(str(test_risk_scores[index]))\n",
    "    row_3.append(str(flag))\n",
    "    row_4.append(str(flag_category))\n",
    "    \n",
    "with open(\"../results/upmc_oc_collagen.csv\", 'w', newline='') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile)\n",
    "    spamwriter.writerow([\"Patient Id\", \"Risk Score\", \"Risk (Numerical)\", \"Risk (Category)\"])\n",
    "    for index in range(0, len(test_oc_files)):    \n",
    "        spamwriter.writerow([row_1[index], row_2[index], row_3[index], row_4[index]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fdadc2",
   "metadata": {},
   "source": [
    "files = glob.glob(\"../results/upmc_oc_collagen_features/*\")\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1e3f30",
   "metadata": {},
   "source": [
    "count_high = 0\n",
    "count_low = 0\n",
    "for file in files:\n",
    "    flag = -1\n",
    "    with open(file, newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile)\n",
    "        for row in spamreader:\n",
    "            if flag == -1:\n",
    "                array = row\n",
    "                flag = 1\n",
    "            else:\n",
    "                array = row\n",
    "                if int(array[1]) == 0:\n",
    "                    count_low += 1\n",
    "                else:\n",
    "                    count_high += 1\n",
    "print(count_low)\n",
    "print(count_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb7c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b60331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e611ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262fd76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48833f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "c = []\n",
    "f_1 = []\n",
    "c_1 = []\n",
    "for index in range(0, len(features)):\n",
    "    f.append(features[index])\n",
    "    c.append((1, 0, 0))\n",
    "for index in range(0, len(test_features)):\n",
    "    f.append(test_features[index])\n",
    "    c.append((0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0853f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = umap.UMAP(n_neighbors=5, random_state=42).fit(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1_transform = trans.transform(f_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9177cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(trans.embedding_[:, 0], trans.embedding_[:, 1], s= 5, c=c, cmap='Spectral')\n",
    "#plt.scatter(f_1_transform[:, 0], f_1_transform[:, 1], s= 5, c=c_1, cmap='Spectral')\n",
    "plt.title(\"UMAP Embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3731d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6adaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce0335c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
